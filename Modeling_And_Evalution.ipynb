{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the preprocessed data\n",
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "X_train shape: (299, 22)\n",
      "X_test shape: (75, 22)\n",
      "y_train shape: (299,)\n",
      "y_test shape: (75,)\n"
     ]
    }
   ],
   "source": [
    "#print the data shapes of the training and testing data\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model evaluation function\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    cv_accuracy = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    cv_log_loss = cross_val_score(model, X, y, cv=5, scoring='neg_log_loss')\n",
    "    \n",
    "    print(f\"\\n{model_name} Cross-Validation Results:\")\n",
    "    print(f\"Mean Accuracy: {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std() * 2:.4f})\")\n",
    "    print(f\"Mean Log Loss: {-cv_log_loss.mean():.4f} (+/- {cv_log_loss.std() * 2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model evaluation function\n",
    "def train_predict_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    y_test_bin = lb.fit_transform(y_test)\n",
    "    roc_auc = roc_auc_score(y_test_bin, y_pred_proba, multi_class='ovr', average='macro')\n",
    "    \n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n{model_name} Test Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Log Loss: {logloss:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'log_loss': logloss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Evaluating Multinomial Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Multinomial Logistic Regression Cross-Validation Results:\n",
      "Mean Accuracy: 0.9131 (+/- 0.0827)\n",
      "Mean Log Loss: 0.4210 (+/- 0.3257)\n",
      "\n",
      "Multinomial Logistic Regression Test Results:\n",
      "Accuracy: 0.9067\n",
      "ROC AUC: 0.9221\n",
      "Log Loss: 0.3854\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82        16\n",
      "           1       0.95      0.95      0.95        43\n",
      "           2       0.93      0.81      0.87        16\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.89      0.88      0.88        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14  1  1]\n",
      " [ 2 41  0]\n",
      " [ 2  1 13]]\n",
      "\n",
      "==================================================\n",
      "Evaluating Decision Tree\n",
      "==================================================\n",
      "\n",
      "Decision Tree Cross-Validation Results:\n",
      "Mean Accuracy: 0.8763 (+/- 0.1255)\n",
      "Mean Log Loss: 3.2240 (+/- 2.6318)\n",
      "\n",
      "Decision Tree Test Results:\n",
      "Accuracy: 0.8933\n",
      "ROC AUC: 0.8873\n",
      "Log Loss: 3.9004\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        16\n",
      "           1       0.95      0.98      0.97        43\n",
      "           2       0.86      0.75      0.80        16\n",
      "\n",
      "    accuracy                           0.89        75\n",
      "   macro avg       0.86      0.85      0.85        75\n",
      "weighted avg       0.89      0.89      0.89        75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  1  2]\n",
      " [ 1 42  0]\n",
      " [ 3  1 12]]\n",
      "\n",
      "==================================================\n",
      "Evaluating Random Forest\n",
      "==================================================\n",
      "\n",
      "Random Forest Cross-Validation Results:\n",
      "Mean Accuracy: 0.9064 (+/- 0.0831)\n",
      "Mean Log Loss: 2.0999 (+/- 3.3583)\n",
      "\n",
      "Random Forest Test Results:\n",
      "Accuracy: 0.8800\n",
      "ROC AUC: 0.9208\n",
      "Log Loss: 2.1108\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.95      0.98      0.97        43\n",
      "           2       0.85      0.69      0.76        16\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.84      0.83      0.83        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  1  2]\n",
      " [ 1 42  0]\n",
      " [ 4  1 11]]\n",
      "\n",
      "==================================================\n",
      "Evaluating XGBoost\n",
      "==================================================\n",
      "\n",
      "XGBoost Cross-Validation Results:\n",
      "Mean Accuracy: 0.9031 (+/- 0.0826)\n",
      "Mean Log Loss: 0.6215 (+/- 0.5153)\n",
      "\n",
      "XGBoost Test Results:\n",
      "Accuracy: 0.9067\n",
      "ROC AUC: 0.9011\n",
      "Log Loss: 0.6244\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        16\n",
      "           1       0.95      0.98      0.97        43\n",
      "           2       0.87      0.81      0.84        16\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.88      0.87      0.87        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  1  2]\n",
      " [ 1 42  0]\n",
      " [ 2  1 13]]\n",
      "\n",
      "==================================================\n",
      "Evaluating Support Vector Machine\n",
      "==================================================\n",
      "\n",
      "Support Vector Machine Cross-Validation Results:\n",
      "Mean Accuracy: 0.9030 (+/- 0.0929)\n",
      "Mean Log Loss: 0.3505 (+/- 0.2622)\n",
      "\n",
      "Support Vector Machine Test Results:\n",
      "Accuracy: 0.8800\n",
      "ROC AUC: 0.9108\n",
      "Log Loss: 0.3997\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.95      0.98      0.97        43\n",
      "           2       0.85      0.69      0.76        16\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.84      0.83      0.83        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  1  2]\n",
      " [ 1 42  0]\n",
      " [ 4  1 11]]\n",
      "\n",
      "==================================================\n",
      "Evaluating K-Nearest Neighbors\n",
      "==================================================\n",
      "\n",
      "K-Nearest Neighbors Cross-Validation Results:\n",
      "Mean Accuracy: 0.8897 (+/- 0.0883)\n",
      "Mean Log Loss: 2.2124 (+/- 3.2205)\n",
      "\n",
      "K-Nearest Neighbors Test Results:\n",
      "Accuracy: 0.8800\n",
      "ROC AUC: 0.9048\n",
      "Log Loss: 3.0221\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.95      0.98      0.97        43\n",
      "           2       0.85      0.69      0.76        16\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.84      0.83      0.83        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  1  2]\n",
      " [ 1 42  0]\n",
      " [ 4  1 11]]\n"
     ]
    }
   ],
   "source": [
    "#list of models to evaluate\n",
    "models = [\n",
    "    (LogisticRegression(multi_class='ovr', random_state=42), \"Multinomial Logistic Regression\"), \n",
    "    (DecisionTreeClassifier(random_state=42), \"Decision Tree\"),\n",
    "    (RandomForestClassifier(n_estimators=100, random_state=42), \"Random Forest\"),\n",
    "    (XGBClassifier(random_state=42), \"XGBoost\"),\n",
    "    (SVC(kernel='rbf', random_state=42, probability=True), \"Support Vector Machine\"),\n",
    "    (KNeighborsClassifier(n_neighbors=5), \"K-Nearest Neighbors\"),\n",
    "   \n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, name in models:\n",
    "    print(f\"\\n{'='*50}\\nEvaluating {name}\\n{'='*50}\")\n",
    "    evaluate_model(model, X_train, y_train, name)\n",
    "    result = train_predict_evaluate(model, X_train, X_test, y_train, y_test, name)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Logistic Regression</th>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.922144</td>\n",
       "      <td>0.385404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.887287</td>\n",
       "      <td>3.900374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.920789</td>\n",
       "      <td>2.110767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.901072</td>\n",
       "      <td>0.624433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.910795</td>\n",
       "      <td>0.399662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.904770</td>\n",
       "      <td>3.022085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 accuracy   roc_auc  log_loss\n",
       "model_name                                                   \n",
       "Multinomial Logistic Regression  0.906667  0.922144  0.385404\n",
       "Decision Tree                    0.893333  0.887287  3.900374\n",
       "Random Forest                    0.880000  0.920789  2.110767\n",
       "XGBoost                          0.906667  0.901072  0.624433\n",
       "Support Vector Machine           0.880000  0.910795  0.399662\n",
       "K-Nearest Neighbors              0.880000  0.904770  3.022085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model by accuracy: Multinomial Logistic Regression\n",
      "Best model by ROC AUC: Multinomial Logistic Regression\n",
      "Best model by log loss: Multinomial Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "#Compare the results of the models\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df = comparison_df.set_index('model_name')\n",
    "print(\"\\nModel Comparison:\")\n",
    "display(comparison_df)\n",
    "\n",
    "best_accuracy = comparison_df['accuracy'].idxmax()\n",
    "best_roc_auc = comparison_df['roc_auc'].idxmax()\n",
    "best_log_loss = comparison_df['log_loss'].idxmin()\n",
    "\n",
    "print(f\"\\nBest model by accuracy: {best_accuracy}\")\n",
    "print(f\"Best model by ROC AUC: {best_roc_auc}\")\n",
    "print(f\"Best model by log loss: {best_log_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
